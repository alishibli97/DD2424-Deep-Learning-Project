{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EGJVhEo3cfw8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rKgxLYn6dhDl"
   },
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BhLeqKV5drPq"
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2Me-dhHgjJ4"
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        mid_channels = 64\n",
    "\n",
    "        # common\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.drop = nn.Dropout(p=0.5,inplace=True)\n",
    "\n",
    "        # downsampling\n",
    "        self.conv1 = nn.Conv2d(n_channels*1, mid_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_channels*2, mid_channels, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(n_channels*4, mid_channels, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(n_channels*8, mid_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        # mid\n",
    "        self.conv_mid = nn.Conv2d(n_channels*16, mid_channels, kernel_size=3, padding=1)\n",
    "\n",
    "        # upsampling\n",
    "        self.deconv4 = nn.ConvTranspose2d(n_channels*8 , mid_channels, kernel_size=3, stride=2, padding=3)\n",
    "        self.deconv4 = nn.ConvTranspose2d(n_channels*4 , mid_channels, kernel_size=3, stride=2, padding=3)\n",
    "        self.deconv4 = nn.ConvTranspose2d(n_channels*2 , mid_channels, kernel_size=3, stride=2, padding=3)\n",
    "        self.deconv4 = nn.ConvTranspose2d(n_channels*1 , mid_channels, kernel_size=3, stride=2, padding=3)\n",
    "\n",
    "        # output layer\n",
    "        self.conv_out = nn.Conv2d(1, mid_channels, kernel_size=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # downsampling\n",
    "        conv1 = self.conv1(x)\n",
    "        conv1 = self.relu(conv1)\n",
    "        conv1 = self.conv1(conv1)\n",
    "        conv1 = self.relu(conv1)\n",
    "        pool1 = self.pool(conv1)\n",
    "        pool1 = self.drop(pool1)\n",
    "\n",
    "        conv2 = self.conv2(pool1)\n",
    "        conv2 = self.relu(conv2)\n",
    "        conv2 = self.conv2(conv2)\n",
    "        conv2 = self.relu(conv2)\n",
    "        pool2 = self.pool(conv2)\n",
    "        pool2 = self.drop(pool2)\n",
    "\n",
    "        conv3 = self.conv3(pool2)\n",
    "        conv3 = self.relu(conv3)\n",
    "        conv3 = self.conv3(conv3)\n",
    "        conv3 = self.relu(conv3)\n",
    "        pool3 = self.pool(conv3)\n",
    "        pool3 = self.drop(pool3)\n",
    "\n",
    "        conv4 = self.conv4(pool3)\n",
    "        conv4 = self.relu(conv4)\n",
    "        conv4 = self.conv4(conv4)\n",
    "        conv4 = self.relu(conv4)\n",
    "        pool4 = self.pool(conv4)\n",
    "        pool4 = self.drop(pool4)\n",
    "\n",
    "        # mid\n",
    "        conv_mid = self.conv_mid(pool4)\n",
    "        conv_mid = self.relu(conv_mid)\n",
    "        conv_mid = self.conv_mid(conv_mid)\n",
    "        conv_mid = self.relu(conv_mid)\n",
    "\n",
    "        # upsampling\n",
    "        deconv4 = self.deconv4(conv_mid)\n",
    "        uconv4 = torch.cat([deconv4, conv4], dim=1)\n",
    "        uconv4 = self.drop(uconv4)\n",
    "        uconv4 = self.conv4(uconv4)\n",
    "        uconv4 = self.relu(uconv4)\n",
    "        uconv4 = self.conv4(uconv4)\n",
    "        uconv4 = self.relu(uconv4)\n",
    "\n",
    "        deconv3 = self.deconv3(uconv4)\n",
    "        uconv3 = torch.cat([deconv3, conv3], dim=1)\n",
    "        uconv3 = self.drop(uconv3)\n",
    "        uconv3 = self.conv3(uconv3)\n",
    "        uconv3 = self.relu(uconv3)\n",
    "        uconv3 = self.conv3(uconv3)\n",
    "        uconv3 = self.relu(uconv3)\n",
    "\n",
    "        deconv2 = self.deconv2(uconv3)\n",
    "        uconv2 = torch.cat([deconv2, conv2], dim=1)\n",
    "        uconv2 = self.drop(uconv2)\n",
    "        uconv2 = self.conv2(uconv2)\n",
    "        uconv2 = self.relu(uconv2)\n",
    "        uconv2 = self.conv2(uconv2)\n",
    "        uconv2 = self.relu(uconv2)\n",
    "\n",
    "        deconv1 = self.deconv1(uconv2)\n",
    "        uconv1 = torch.cat([deconv1, conv1], dim=1)\n",
    "        uconv1 = self.drop(uconv1)\n",
    "        uconv1 = self.conv1(uconv1)\n",
    "        uconv1 = self.relu(uconv1)\n",
    "        uconv1 = self.conv1(uconv1)\n",
    "        uconv1 = self.relu(uconv1)\n",
    "\n",
    "        # output layer\n",
    "        out = self.conv_out(uconv1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "unet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
