{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader code\n",
    "from unet import *\n",
    "from segmentation_dataset import SegmentationDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from loguru import logger\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f\n",
    "\n",
    "train_path = \"small_dataset/images/nir/\"\n",
    "val_path = \"small_dataset/images/nir/\"\n",
    "test_path = \"small_dataset/images/nir/\"\n",
    "\n",
    "train_labels_path = \"small_dataset/labels/\"\n",
    "val_labels_path = \"small_dataset/labels/\"\n",
    "test_labels_path = \"small_dataset/labels/\"\n",
    "\n",
    "train_img_names_index = os.listdir(train_path)[:10]\n",
    "val_img_names_index = os.listdir(val_path)[:10]\n",
    "test_img_names_index = os.listdir(test_path)[:10]\n",
    "\n",
    "labels_one_hot = {}\n",
    "k = 8\n",
    "i=0\n",
    "for label in listdir_nohidden(train_labels_path):\n",
    "    if label!=\"storm_damage\":\n",
    "        labels_one_hot[label] = np.zeros((k,))\n",
    "        labels_one_hot[label][i] = 1\n",
    "        i+=1\n",
    "\n",
    "train_dataset = SegmentationDataset(train_img_names_index, labels_one_hot, train_path, train_labels_path, use_cache=True)\n",
    "val_dataset = SegmentationDataset(val_img_names_index, labels_one_hot, val_path, val_labels_path, use_cache=True)\n",
    "test_dataset = SegmentationDataset(test_img_names_index, labels_one_hot, test_path, test_labels_path, use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda used\n"
     ]
    }
   ],
   "source": [
    "# SETTINGS\n",
    "Use_GPU = True\n",
    "Lr = 1e-3\n",
    "channels = 1  # NIR vs RGB\n",
    "classes = 10  # outputs (9 labels + 1 background)\n",
    "maxEpochs = 10\n",
    "batch_size = 5\n",
    "shuffle = True\n",
    "\n",
    "# Code \n",
    "if Use_GPU: \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print('cuda used')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "# initalize model \n",
    "\n",
    "# fix activationfunc, dropout and other settings for model as parameters later \n",
    "\n",
    "model = UNet(channels, classes).to(device)\n",
    "\n",
    "trainValRate = 0.7  # not in use\n",
    "lrRatesplan = None  # not in use\n",
    "activation = \"relu\"  # not in use \n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.SGD(model.parameters(), Lr)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Training accuracy for batch 0: 0.014471\n",
      "Training loss for batch 0: 1.527761\n",
      "1\n",
      "Training accuracy for batch 1: 0.011566\n",
      "Training loss for batch 1: 0.325536\n",
      "training Epoch :0max Epochs\n",
      "0\n",
      "Training accuracy for batch 0: 0.010802\n",
      "Training loss for batch 0: 0.177954\n",
      "1\n",
      "Training accuracy for batch 1: 0.010440\n",
      "Training loss for batch 1: 0.110900\n",
      "0\n",
      "Training accuracy for batch 0: 0.009852\n",
      "Training loss for batch 0: 0.076835\n",
      "1\n",
      "Training accuracy for batch 1: 0.011380\n",
      "Training loss for batch 1: 0.085639\n",
      "0\n",
      "Training accuracy for batch 0: 0.011617\n",
      "Training loss for batch 0: 0.057009\n",
      "1\n",
      "Training accuracy for batch 1: 0.009606\n",
      "Training loss for batch 1: 0.057231\n",
      "0\n",
      "Training accuracy for batch 0: 0.011552\n",
      "Training loss for batch 0: 0.054803\n",
      "1\n",
      "Training accuracy for batch 1: 0.009674\n",
      "Training loss for batch 1: 0.029119\n",
      "0\n",
      "Training accuracy for batch 0: 0.010291\n",
      "Training loss for batch 0: 0.026659\n",
      "1\n",
      "Training accuracy for batch 1: 0.010950\n",
      "Training loss for batch 1: 0.041559\n",
      "0\n",
      "Training accuracy for batch 0: 0.010348\n",
      "Training loss for batch 0: 0.024386\n",
      "1\n",
      "Training accuracy for batch 1: 0.010893\n",
      "Training loss for batch 1: 0.032452\n",
      "0\n",
      "Training accuracy for batch 0: 0.010224\n",
      "Training loss for batch 0: 0.027590\n",
      "1\n",
      "Training accuracy for batch 1: 0.011016\n",
      "Training loss for batch 1: 0.021321\n",
      "0\n",
      "Training accuracy for batch 0: 0.010351\n",
      "Training loss for batch 0: 0.014535\n",
      "1\n",
      "Training accuracy for batch 1: 0.010890\n",
      "Training loss for batch 1: 0.027580\n",
      "0\n",
      "Training accuracy for batch 0: 0.010716\n",
      "Training loss for batch 0: 0.024342\n",
      "1\n",
      "Training accuracy for batch 1: 0.010527\n",
      "Training loss for batch 1: 0.013158\n",
      "0\n",
      "Training accuracy for batch 0: 0.010967\n",
      "Training loss for batch 0: 0.019197\n",
      "1\n",
      "Training accuracy for batch 1: 0.010273\n",
      "Training loss for batch 1: 0.014321\n",
      "training Epoch :10max Epochs\n",
      "0\n",
      "Training accuracy for batch 0: 0.010191\n",
      "Training loss for batch 0: 0.017260\n",
      "1\n",
      "Training accuracy for batch 1: 0.011048\n",
      "Training loss for batch 1: 0.013351\n",
      "0\n",
      "Training accuracy for batch 0: 0.011280\n",
      "Training loss for batch 0: 0.014593\n",
      "1\n",
      "Training accuracy for batch 1: 0.009954\n",
      "Training loss for batch 1: 0.013176\n",
      "0\n",
      "Training accuracy for batch 0: 0.011543\n",
      "Training loss for batch 0: 0.016084\n",
      "1\n",
      "Training accuracy for batch 1: 0.009683\n",
      "Training loss for batch 1: 0.008900\n",
      "0\n",
      "Training accuracy for batch 0: 0.010256\n",
      "Training loss for batch 0: 0.009022\n",
      "1\n",
      "Training accuracy for batch 1: 0.010984\n",
      "Training loss for batch 1: 0.014495\n",
      "0\n",
      "Training accuracy for batch 0: 0.010914\n",
      "Training loss for batch 0: 0.013739\n",
      "1\n",
      "Training accuracy for batch 1: 0.010327\n",
      "Training loss for batch 1: 0.008189\n",
      "0\n",
      "Training accuracy for batch 0: 0.010923\n",
      "Training loss for batch 0: 0.009022\n",
      "1\n",
      "Training accuracy for batch 1: 0.010318\n",
      "Training loss for batch 1: 0.011713\n",
      "0\n",
      "Training accuracy for batch 0: 0.010308\n",
      "Training loss for batch 0: 0.010791\n",
      "1\n",
      "Training accuracy for batch 1: 0.010933\n",
      "Training loss for batch 1: 0.008630\n",
      "0\n",
      "Training accuracy for batch 0: 0.011535\n",
      "Training loss for batch 0: 0.008193\n",
      "1\n",
      "Training accuracy for batch 1: 0.009691\n",
      "Training loss for batch 1: 0.010275\n",
      "0\n",
      "Training accuracy for batch 0: 0.010857\n",
      "Training loss for batch 0: 0.011476\n",
      "1\n",
      "Training accuracy for batch 1: 0.010385\n",
      "Training loss for batch 1: 0.005639\n",
      "0\n",
      "Training accuracy for batch 0: 0.010991\n",
      "Training loss for batch 0: 0.007740\n",
      "1\n",
      "Training accuracy for batch 1: 0.010250\n",
      "Training loss for batch 1: 0.008641\n",
      "training Epoch :20max Epochs\n",
      "0\n",
      "Training accuracy for batch 0: 0.010224\n",
      "Training loss for batch 0: 0.008879\n",
      "1\n",
      "Training accuracy for batch 1: 0.011016\n",
      "Training loss for batch 1: 0.006728\n",
      "0\n",
      "Training accuracy for batch 0: 0.010342\n",
      "Training loss for batch 0: 0.008896\n",
      "1\n",
      "Training accuracy for batch 1: 0.010900\n",
      "Training loss for batch 1: 0.005975\n",
      "0\n",
      "Training accuracy for batch 0: 0.010414\n",
      "Training loss for batch 0: 0.008508\n",
      "1\n",
      "Training accuracy for batch 1: 0.010828\n",
      "Training loss for batch 1: 0.005671\n",
      "0\n",
      "Training accuracy for batch 0: 0.010561\n",
      "Training loss for batch 0: 0.005166\n",
      "1\n",
      "Training accuracy for batch 1: 0.010682\n",
      "Training loss for batch 1: 0.008327\n",
      "0\n",
      "Training accuracy for batch 0: 0.011175\n",
      "Training loss for batch 0: 0.007470\n",
      "1\n",
      "Training accuracy for batch 1: 0.010062\n",
      "Training loss for batch 1: 0.005363\n",
      "0\n",
      "Training accuracy for batch 0: 0.010884\n",
      "Training loss for batch 0: 0.007249\n",
      "1\n",
      "Training accuracy for batch 1: 0.010357\n",
      "Training loss for batch 1: 0.005131\n",
      "0\n",
      "Training accuracy for batch 0: 0.010485\n",
      "Training loss for batch 0: 0.007214\n",
      "1\n",
      "Training accuracy for batch 1: 0.010758\n",
      "Training loss for batch 1: 0.004777\n",
      "0\n",
      "Training accuracy for batch 0: 0.011019\n",
      "Training loss for batch 0: 0.004010\n",
      "1\n",
      "Training accuracy for batch 1: 0.010221\n",
      "Training loss for batch 1: 0.007667\n",
      "0\n",
      "Training accuracy for batch 0: 0.011092\n",
      "Training loss for batch 0: 0.006464\n",
      "1\n",
      "Training accuracy for batch 1: 0.010146\n",
      "Training loss for batch 1: 0.004557\n",
      "0\n",
      "Training accuracy for batch 0: 0.010510\n",
      "Training loss for batch 0: 0.005756\n",
      "1\n",
      "Training accuracy for batch 1: 0.010733\n",
      "Training loss for batch 1: 0.004975\n",
      "training Epoch :30max Epochs\n",
      "0\n",
      "Training accuracy for batch 0: 0.010733\n",
      "Training loss for batch 0: 0.004885\n",
      "1\n",
      "Training accuracy for batch 1: 0.010510\n",
      "Training loss for batch 1: 0.005485\n",
      "0\n",
      "Training accuracy for batch 0: 0.011286\n",
      "Training loss for batch 0: 0.006925\n",
      "1\n",
      "Training accuracy for batch 1: 0.009948\n",
      "Training loss for batch 1: 0.002840\n",
      "0\n",
      "Training accuracy for batch 0: 0.010146\n",
      "Training loss for batch 0: 0.004052\n",
      "1\n",
      "Training accuracy for batch 1: 0.011092\n",
      "Training loss for batch 1: 0.005600\n",
      "0\n",
      "Training accuracy for batch 0: 0.010758\n",
      "Training loss for batch 0: 0.003809\n",
      "1\n",
      "Training accuracy for batch 1: 0.010485\n",
      "Training loss for batch 1: 0.005654\n",
      "0\n",
      "Training accuracy for batch 0: 0.010736\n",
      "Training loss for batch 0: 0.003419\n",
      "1\n",
      "Training accuracy for batch 1: 0.010507\n",
      "Training loss for batch 1: 0.005767\n",
      "0\n",
      "Training accuracy for batch 0: 0.010840\n",
      "Training loss for batch 0: 0.003665\n",
      "1\n",
      "Training accuracy for batch 1: 0.010402\n",
      "Training loss for batch 1: 0.005270\n",
      "0\n",
      "Training accuracy for batch 0: 0.009665\n",
      "Training loss for batch 0: 0.004990\n",
      "1\n",
      "Training accuracy for batch 1: 0.011560\n",
      "Training loss for batch 1: 0.003772\n",
      "0\n",
      "Training accuracy for batch 0: 0.011116\n",
      "Training loss for batch 0: 0.005124\n",
      "1\n",
      "Training accuracy for batch 1: 0.010123\n",
      "Training loss for batch 1: 0.003196\n",
      "0\n",
      "Training accuracy for batch 0: 0.010181\n",
      "Training loss for batch 0: 0.002915\n",
      "1\n",
      "Training accuracy for batch 1: 0.011058\n",
      "Training loss for batch 1: 0.005174\n",
      "0\n",
      "Training accuracy for batch 0: 0.010991\n",
      "Training loss for batch 0: 0.003482\n",
      "1\n",
      "Training accuracy for batch 1: 0.010250\n",
      "Training loss for batch 1: 0.004544\n",
      "training Epoch :40max Epochs\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6ac77e0932be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-6ac77e0932be>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"trained_model.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;31m# Copy to a buffer, then serialize that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_should_read_directly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m             \u001b[0mbuf_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainingAcc = []\n",
    "trainingLoss = []\n",
    "validationAcc = []\n",
    "validationLoss = []\n",
    "\n",
    "def itterProgress(x, text = \"training\"):\n",
    "    return tqdm(enumerate(x), text, total = len(x))\n",
    "\n",
    "def run(): \n",
    "    # itter = itterProgress(trainX)\n",
    "\n",
    "    for epoch in range(maxEpochs):\n",
    "        train(epoch)\n",
    "\n",
    "    torch.save(model.state_dict(), \"trained_model.pth\")\n",
    "    \n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for i, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "        indata, target = batch_x.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        indata = indata.unsqueeze(1)\n",
    "        out = model(indata)\n",
    "        out_softmax = torch.softmax(out, 1)\n",
    "        img = postprocess(out_softmax)\n",
    "        \n",
    "        train_acc = iou(img, target)\n",
    "        loss = criterion(out, target)\n",
    "        train_loss = loss.item()\n",
    "        \n",
    "        trainingAcc.append(train_acc)\n",
    "        trainingLoss.append(train_loss)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        val_acc, val_loss = validate()\n",
    "\n",
    "        validationAcc.append(val_acc)\n",
    "        validationLoss.append(val_loss)\n",
    "\n",
    "        logger.info(f\"Epoch {epoch} batch {i+1}/{len(train_dataloader)} loss={train_loss} acc={train_acc} val_loss={val_loss} val_acc={val_acc}\")\n",
    "\n",
    "        if val_loss > np.mean(validationLoss):\n",
    "            print(\"Overfitting detected\")\n",
    "            break\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    validationAcc_temp = []\n",
    "    validationLoss_temp = []\n",
    "    for i, (batch_x, batch_y) in enumerate(val_dataloader):\n",
    "        indata, target = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            indata = indata.unsqueeze(1)\n",
    "            out = model.forward(indata)\n",
    "            out_softmax = torch.softmax(out, 1)\n",
    "            img = postprocess(out_softmax)\n",
    "            \n",
    "            val_acc = iou(img, target)            \n",
    "            loss = criterion(out, target)\n",
    "            val_loss = loss.item()\n",
    "\n",
    "            validationAcc_temp.append(val_acc)\n",
    "            validationLoss_temp.append(val_loss)\n",
    "    \n",
    "    return np.mean(validationAcc_temp),np.mean(validationLoss_temp)\n",
    "\n",
    "def postprocess(img):\n",
    "    img = torch.argmax(img, dim=1)\n",
    "    img = img.cpu().numpy()\n",
    "    img = np.squeeze(img)\n",
    "    img = torch.from_numpy(img).type(torch.int64)\n",
    "    img = img.to(device)\n",
    "    # img = re_normalize(img)\n",
    "    return img\n",
    "\n",
    "def iou(prediction, target):\n",
    "    eps = 0\n",
    "    score = 0\n",
    "\n",
    "    for k in range(1, 10):\n",
    "        intersection = torch.sum((prediction==target) * (target==k)).item()\n",
    "        union = torch.sum(prediction==k).item() + torch.sum(target==k).item()\n",
    "        iou_k = 0 if intersection == 0 else (intersection + eps) / (union + eps)\n",
    "        score += iou_k\n",
    "\n",
    "    score = score / 9\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc2ec1a9eb0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(validationLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainingLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(validationAcc)\n",
    "plt.plot(trainingAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "for i in range(10):\n",
    "    probs = out[0][i].cpu()\n",
    "    probs = probs.detach().numpy()\n",
    "    plt.show()\n",
    "    plt.imshow(probs, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rescale\n",
    "\n",
    "x = torch.Tensor([[0, 1, 1, 0], [1, 1, 0, 0], [1, 1, 1, 1], [1, 1, 1, 1]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "\n",
    "#T = torch.zeros(3, 200, 120)\n",
    "# print(T.shape)\n",
    "\n",
    "x = rescale(x, 1/2, order=0, anti_aliasing=False)\n",
    "\n",
    "print(x.shape)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "778c709b60e40e6eabd44100ef7be5ae1872ed437ec46128456490bb70151712"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
