{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader code\n",
    "from unet import *\n",
    "from segmentation_dataset import SegmentationDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f\n",
    "\n",
    "train_path = \"small_dataset/images/nir/\"\n",
    "val_path = \"small_dataset/images/nir/\"\n",
    "test_path = \"small_dataset/images/nir/\"\n",
    "\n",
    "train_labels_path = \"small_dataset/labels/\"\n",
    "val_labels_path = \"small_dataset/labels/\"\n",
    "test_labels_path = \"small_dataset/labels/\"\n",
    "\n",
    "train_img_names_index = os.listdir(train_path)[:10]\n",
    "val_img_names_index = os.listdir(val_path)[:10]\n",
    "test_img_names_index = os.listdir(test_path)[:10]\n",
    "\n",
    "labels_one_hot = {}\n",
    "k = 9\n",
    "for i, label in enumerate(listdir_nohidden(train_labels_path)):\n",
    "    labels_one_hot[label] = np.zeros((k,))\n",
    "    labels_one_hot[label][i] = 1\n",
    "\n",
    "train_dataset = SegmentationDataset(train_img_names_index, labels_one_hot, train_path, train_labels_path, use_cache=True)\n",
    "val_dataset = SegmentationDataset(val_img_names_index, labels_one_hot, val_path, val_labels_path, use_cache=True)\n",
    "test_dataset = SegmentationDataset(test_img_names_index, labels_one_hot, test_path, test_labels_path, use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETTINGS\n",
    "Use_GPU = True\n",
    "Lr = 1e-3\n",
    "channels = 1  # NIR vs RGB\n",
    "classes = 10  # outputs (9 labels + 1 background)\n",
    "maxEpochs = 10\n",
    "batch_size = 5\n",
    "shuffle = True\n",
    "\n",
    "#Code \n",
    "if Use_GPU: \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print('cuda used')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "#initalize model \n",
    "\n",
    "#fix activationfunc, dropout and other settings for model as parameters later \n",
    "\n",
    "model = UNet(channels, classes).to(device)\n",
    "\n",
    "trainValRate = 0.7 #not in use\n",
    "lrRatesplan = None #not in use\n",
    "activation = \"relu\" #not in use \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), Lr)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingAcc = []\n",
    "trainingLoss = []\n",
    "validationAcc = []\n",
    "validationLoss = []\n",
    "validate_go = False  # True\n",
    "\n",
    "def itterProgress(x, text = \"training\"):\n",
    "    return tqdm(enumerate(x), text, total = len(x))\n",
    "\n",
    "def run(): \n",
    "#     itter = itterProgress(trainX)\n",
    "    \n",
    "    \n",
    "    for epoch in range(maxEpochs):\n",
    "        train()\n",
    "        if epoch % 10 == 0: \n",
    "            print(\"training Epoch :\" + str(epoch)  + \"max Epochs\")\n",
    "\n",
    "        val_loss = validate()\n",
    "        if val_loss > np.mean(validationLoss):\n",
    "            print(\"Overfitting detected\")\n",
    "            break\n",
    "            \n",
    "        torch.save(model.state_dict(), \"trained_model.pth\")\n",
    "    \n",
    "\n",
    "def train(): \n",
    "    model.train()\n",
    "    for i, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "        print(i)\n",
    "        indata, target = batch_x.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        indata = indata.unsqueeze(1)\n",
    "        out = model(indata)\n",
    "\n",
    "        out_softmax = torch.softmax(out, 1)\n",
    "        img = postprocess(out_softmax)\n",
    "        acc = iou(img, target)\n",
    "        print('Training accuracy for batch %i: %f' % (i, acc))\n",
    "        trainingAcc.append(acc)\n",
    "\n",
    "        # plt.imshow(target[0], cmap='gray')\n",
    "        # plt.show()\n",
    "        # plt.imshow(indata[0][0], cmap='gray')\n",
    "        # plt.show()\n",
    "        # plt.imshow(img[0], cmap='gray')\n",
    "        # plt.show()\n",
    "        \n",
    "        \n",
    "        loss = criterion(out, target)\n",
    "        loss_value = loss.item()\n",
    "        print('Training loss for batch %i: %f' % (i, loss_value))\n",
    "        trainingLoss.append(loss_value)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    validationLoss_temp = []    \n",
    "    for i, (batch_x, batch_y) in enumerate(val_dataloader):\n",
    "        indata, target = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            indata = indata.unsqueeze(1)\n",
    "            out = model.forward(indata)\n",
    "            \n",
    "            out_softmax = torch.softmax(out, 1)\n",
    "            img = postprocess(out_softmax)\n",
    "            acc = iou(img, target)\n",
    "            print('Validation accuracy: ' + str(acc))\n",
    "            # validationAcc.append(acc)\n",
    "            \n",
    "            loss = criterion(out, target)\n",
    "            loss_value = loss.item()\n",
    "            validationLoss.append(loss_value)\n",
    "            validationLoss_temp.append(loss_value)\n",
    "    \n",
    "    return np.mean(validationLoss_temp)\n",
    "\n",
    "def postprocess(img):\n",
    "    img = torch.argmax(img, dim=1)\n",
    "    img = img.cpu().numpy()\n",
    "    img = np.squeeze(img)\n",
    "    img = torch.from_numpy(img).type(torch.int64)\n",
    "    # img = re_normalize(img)\n",
    "    return img\n",
    "\n",
    "def iou(prediction, target):\n",
    "    eps = 0\n",
    "    score = 0\n",
    "    # print(torch.unique(prediction))\n",
    "    # print(torch.unique(target))\n",
    "    for k in range(1, 10):\n",
    "        intersection = torch.sum((prediction==target) * (target==k)).item()\n",
    "        # print('intersection: ' + str(intersection))\n",
    "        union = torch.sum(prediction==k).item() + torch.sum(target==k).item()\n",
    "        # print('union: ' + str(union))\n",
    "        iou_k = 0 if intersection == 0 else (intersection + eps) / (union + eps)\n",
    "        score += iou_k\n",
    "\n",
    "    score = score / 9\n",
    "    return score\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(validationLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainingLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(validationAcc)\n",
    "plt.plot(trainingAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "for i in range(10):\n",
    "    probs = out[0][i].cpu()\n",
    "    probs = probs.detach().numpy()\n",
    "    plt.show()\n",
    "    plt.imshow(probs, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rescale\n",
    "\n",
    "x = torch.Tensor([[0, 1, 1, 0], [1, 1, 0, 0], [1, 1, 1, 1], [1, 1, 1, 1]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "\n",
    "#T = torch.zeros(3, 200, 120)\n",
    "# print(T.shape)\n",
    "\n",
    "x = rescale(x, 1/2, order=0, anti_aliasing=False)\n",
    "\n",
    "print(x.shape)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python391jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}