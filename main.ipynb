{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-05-23 21:04:32.185 | INFO     | segmentation_dataset:__init__:27 - Reading train image 0 out of 10\n",
      "2021-05-23 21:04:32.234 | INFO     | segmentation_dataset:__init__:27 - Reading train image 1 out of 10\n",
      "2021-05-23 21:04:32.271 | INFO     | segmentation_dataset:__init__:27 - Reading train image 2 out of 10\n",
      "2021-05-23 21:04:32.301 | INFO     | segmentation_dataset:__init__:27 - Reading train image 3 out of 10\n",
      "2021-05-23 21:04:32.331 | INFO     | segmentation_dataset:__init__:27 - Reading train image 4 out of 10\n",
      "2021-05-23 21:04:32.363 | INFO     | segmentation_dataset:__init__:27 - Reading train image 5 out of 10\n",
      "2021-05-23 21:04:32.392 | INFO     | segmentation_dataset:__init__:27 - Reading train image 6 out of 10\n",
      "2021-05-23 21:04:32.425 | INFO     | segmentation_dataset:__init__:27 - Reading train image 7 out of 10\n",
      "2021-05-23 21:04:32.458 | INFO     | segmentation_dataset:__init__:27 - Reading train image 8 out of 10\n",
      "2021-05-23 21:04:32.489 | INFO     | segmentation_dataset:__init__:27 - Reading train image 9 out of 10\n",
      "2021-05-23 21:04:32.523 | INFO     | segmentation_dataset:__init__:27 - Reading validation image 0 out of 10\n",
      "2021-05-23 21:04:32.554 | INFO     | segmentation_dataset:__init__:27 - Reading validation image 1 out of 10\n",
      "2021-05-23 21:04:32.579 | INFO     | segmentation_dataset:__init__:27 - Reading validation image 2 out of 10\n",
      "2021-05-23 21:04:32.605 | INFO     | segmentation_dataset:__init__:27 - Reading validation image 3 out of 10\n",
      "2021-05-23 21:04:32.636 | INFO     | segmentation_dataset:__init__:27 - Reading validation image 4 out of 10\n",
      "2021-05-23 21:04:32.685 | INFO     | segmentation_dataset:__init__:27 - Reading validation image 5 out of 10\n",
      "2021-05-23 21:04:32.710 | INFO     | segmentation_dataset:__init__:27 - Reading validation image 6 out of 10\n",
      "2021-05-23 21:04:32.735 | INFO     | segmentation_dataset:__init__:27 - Reading validation image 7 out of 10\n",
      "2021-05-23 21:04:32.759 | INFO     | segmentation_dataset:__init__:27 - Reading validation image 8 out of 10\n",
      "2021-05-23 21:04:32.785 | INFO     | segmentation_dataset:__init__:27 - Reading validation image 9 out of 10\n",
      "2021-05-23 21:04:32.809 | INFO     | segmentation_dataset:__init__:27 - Reading test image 0 out of 10\n",
      "2021-05-23 21:04:32.833 | INFO     | segmentation_dataset:__init__:27 - Reading test image 1 out of 10\n",
      "2021-05-23 21:04:32.860 | INFO     | segmentation_dataset:__init__:27 - Reading test image 2 out of 10\n",
      "2021-05-23 21:04:32.884 | INFO     | segmentation_dataset:__init__:27 - Reading test image 3 out of 10\n",
      "2021-05-23 21:04:32.908 | INFO     | segmentation_dataset:__init__:27 - Reading test image 4 out of 10\n",
      "2021-05-23 21:04:32.932 | INFO     | segmentation_dataset:__init__:27 - Reading test image 5 out of 10\n",
      "2021-05-23 21:04:32.955 | INFO     | segmentation_dataset:__init__:27 - Reading test image 6 out of 10\n",
      "2021-05-23 21:04:32.979 | INFO     | segmentation_dataset:__init__:27 - Reading test image 7 out of 10\n",
      "2021-05-23 21:04:33.005 | INFO     | segmentation_dataset:__init__:27 - Reading test image 8 out of 10\n",
      "2021-05-23 21:04:33.036 | INFO     | segmentation_dataset:__init__:27 - Reading test image 9 out of 10\n"
     ]
    }
   ],
   "source": [
    "# dataloader code\n",
    "from unet import *\n",
    "from segmentation_dataset import SegmentationDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from loguru import logger\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f\n",
    "\n",
    "train_path = \"small_dataset/images/nir/\"\n",
    "val_path = \"small_dataset/images/nir/\"\n",
    "test_path = \"small_dataset/images/nir/\"\n",
    "\n",
    "train_labels_path = \"small_dataset/labels/\"\n",
    "val_labels_path = \"small_dataset/labels/\"\n",
    "test_labels_path = \"small_dataset/labels/\"\n",
    "\n",
    "train_img_names_index = os.listdir(train_path)[:10]\n",
    "val_img_names_index = os.listdir(val_path)[:10]\n",
    "test_img_names_index = os.listdir(test_path)[:10]\n",
    "\n",
    "labels_one_hot = {}\n",
    "k = 8\n",
    "i=0\n",
    "for label in listdir_nohidden(train_labels_path):\n",
    "    if label!=\"storm_damage\":\n",
    "        labels_one_hot[label] = np.zeros((k,))\n",
    "        labels_one_hot[label][i] = 1\n",
    "        i+=1\n",
    "\n",
    "train_dataset = SegmentationDataset(\"train\", train_img_names_index, labels_one_hot, train_path, train_labels_path, use_cache=True)\n",
    "val_dataset = SegmentationDataset(\"validation\", val_img_names_index, labels_one_hot, val_path, val_labels_path, use_cache=True)\n",
    "test_dataset = SegmentationDataset(\"test\", test_img_names_index, labels_one_hot, test_path, test_labels_path, use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTINGS\n",
    "Use_GPU = True\n",
    "Lr = 1e-3\n",
    "channels = 1  # NIR vs RGB\n",
    "classes = 9  # outputs (9 labels + 1 background)\n",
    "maxEpochs = 10\n",
    "batch_size = 5\n",
    "shuffle = True\n",
    "\n",
    "# Code \n",
    "if Use_GPU: \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print('cuda used')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "# initalize model \n",
    "\n",
    "# fix activationfunc, dropout and other settings for model as parameters later \n",
    "\n",
    "model = UNet(channels, classes).to(device)\n",
    "\n",
    "trainValRate = 0.7  # not in use\n",
    "lrRatesplan = None  # not in use\n",
    "activation = \"relu\"  # not in use \n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.SGD(model.parameters(), Lr)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainingAcc = []\n",
    "trainingLoss = []\n",
    "validationAcc = []\n",
    "validationLoss = []\n",
    "\n",
    "def itterProgress(x, text = \"training\"):\n",
    "    return tqdm(enumerate(x), text, total = len(x))\n",
    "\n",
    "def run(): \n",
    "    # itter = itterProgress(trainX)\n",
    "\n",
    "    for epoch in range(maxEpochs):\n",
    "        train(epoch)\n",
    "\n",
    "    torch.save(model.state_dict(), \"trained_model.pth\")\n",
    "    \n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for i, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "        indata, target = batch_x.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        indata = indata.unsqueeze(1)\n",
    "        out = model(indata)\n",
    "        out_softmax = torch.softmax(out, 1)\n",
    "        img = postprocess(out_softmax)\n",
    "        \n",
    "        train_acc = iou(img, target)\n",
    "        loss = criterion(out, target)\n",
    "        train_loss = loss.item()\n",
    "        \n",
    "        trainingAcc.append(train_acc)\n",
    "        trainingLoss.append(train_loss)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        val_acc, val_loss = validate()\n",
    "\n",
    "        validationAcc.append(val_acc)\n",
    "        validationLoss.append(val_loss)\n",
    "\n",
    "        logger.info(f\"Epoch {epoch} batch {i+1}/{len(train_dataloader)} loss={train_loss} acc={train_acc} val_loss={val_loss} val_acc={val_acc}\")\n",
    "\n",
    "        if val_loss > np.mean(validationLoss):\n",
    "            print(\"Overfitting detected\")\n",
    "            break\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    validationAcc_temp = []\n",
    "    validationLoss_temp = []\n",
    "    for i, (batch_x, batch_y) in enumerate(val_dataloader):\n",
    "        indata, target = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            indata = indata.unsqueeze(1)\n",
    "            out = model.forward(indata)\n",
    "            out_softmax = torch.softmax(out, 1)\n",
    "            img = postprocess(out_softmax)\n",
    "            \n",
    "            val_acc = iou(img, target)            \n",
    "            loss = criterion(out, target)\n",
    "            val_loss = loss.item()\n",
    "\n",
    "            validationAcc_temp.append(val_acc)\n",
    "            validationLoss_temp.append(val_loss)\n",
    "    \n",
    "    return np.mean(validationAcc_temp),np.mean(validationLoss_temp)\n",
    "\n",
    "def postprocess(img):\n",
    "    img = torch.argmax(img, dim=1)\n",
    "    img = img.cpu().numpy()\n",
    "    img = np.squeeze(img)\n",
    "    img = torch.from_numpy(img).type(torch.int64)\n",
    "    img = img.to(device)\n",
    "    # img = re_normalize(img)\n",
    "    return img\n",
    "\n",
    "def iou(prediction, target):\n",
    "    eps = 0\n",
    "    score = 0\n",
    "\n",
    "    for k in range(1, 10):\n",
    "        intersection = torch.sum((prediction==target) * (target==k)).item()\n",
    "        union = torch.sum(prediction==k).item() + torch.sum(target==k).item()\n",
    "        iou_k = 0 if intersection == 0 else (intersection + eps) / (union + eps)\n",
    "        score += iou_k\n",
    "\n",
    "    score = score / 9\n",
    "    return score\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(validationLoss,color)\n",
    "plt.plot(trainingLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_y = next(iter(train_dataloader))\n",
    "x = batch_x[0]\n",
    "y = batch_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = batch_x.to(device)\n",
    "indata = batch_x.unsqueeze(1)\n",
    "out = model(indata)\n",
    "out_softmax = torch.softmax(out, 1)\n",
    "img = postprocess(out_softmax)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "for i in range(10):\n",
    "    probs = out[0][i].cpu()\n",
    "    probs = probs.detach().numpy()\n",
    "    plt.show()\n",
    "    plt.imshow(probs, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python380jvsc74a57bd0778c709b60e40e6eabd44100ef7be5ae1872ed437ec46128456490bb70151712",
   "display_name": "Python 3.8.0 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "778c709b60e40e6eabd44100ef7be5ae1872ed437ec46128456490bb70151712"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}