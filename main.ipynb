{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader code\n",
    "from unet import *\n",
    "from segmentation_dataset import SegmentationDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from loguru import logger\n",
    "import random\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f\n",
    "\n",
    "train_path = \"small_dataset/images/nir/\"\n",
    "val_path = \"small_dataset/images/nir/\"\n",
    "test_path = \"small_dataset/images/nir/\"\n",
    "\n",
    "train_labels_path = \"small_dataset/labels/\"\n",
    "val_labels_path = \"small_dataset/labels/\"\n",
    "test_labels_path = \"small_dataset/labels/\"\n",
    "\n",
    "train = os.listdir(train_path)\n",
    "val = os.listdir(val_path)\n",
    "test = os.listdir(test_path)\n",
    "\n",
    "random.shuffle(train)\n",
    "random.shuffle(val)\n",
    "random.shuffle(test)\n",
    "\n",
    "train_img_names_index = train[:10]\n",
    "val_img_names_index = val[:10]\n",
    "test_img_names_index = test[:10]\n",
    "\n",
    "labels_one_hot = {}\n",
    "k = 8\n",
    "i=0\n",
    "for label in listdir_nohidden(train_labels_path):\n",
    "    if label!=\"storm_damage\":\n",
    "        labels_one_hot[label] = np.zeros((k,))\n",
    "        labels_one_hot[label][i] = 1\n",
    "        i+=1\n",
    "\n",
    "train_dataset = SegmentationDataset(\"train\", train_img_names_index, labels_one_hot, train_path, train_labels_path, use_cache=True)\n",
    "val_dataset = SegmentationDataset(\"validation\", val_img_names_index, labels_one_hot, val_path, val_labels_path, use_cache=True)\n",
    "test_dataset = SegmentationDataset(\"test\", test_img_names_index, labels_one_hot, test_path, test_labels_path, use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTINGS\n",
    "Use_GPU = True\n",
    "Lr = 1e-3\n",
    "channels = 1  # NIR vs RGB\n",
    "classes = 9  # outputs (9 labels + 1 background)\n",
    "maxEpochs = 10\n",
    "batch_size = 5\n",
    "shuffle = True\n",
    "\n",
    "# Code \n",
    "if Use_GPU: \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print('cuda used')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "# initalize model \n",
    "\n",
    "# fix activationfunc, dropout and other settings for model as parameters later \n",
    "\n",
    "model = UNet(channels, classes).to(device)\n",
    "\n",
    "trainValRate = 0.7  # not in use\n",
    "lrRatesplan = None  # not in use\n",
    "activation = \"relu\"  # not in use \n",
    "\n",
    "class_weights = torch.FloatTensor([1]+[5]*8)#.cuda()\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# criterion = torch.nn.CrossEntropyLoss()#ignore_index=0)\n",
    "optimizer = torch.optim.SGD(model.parameters(), Lr)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainingAcc = []\n",
    "trainingLoss = []\n",
    "validationAcc = []\n",
    "validationLoss = []\n",
    "\n",
    "def itterProgress(x, text = \"training\"):\n",
    "    return tqdm(enumerate(x), text, total = len(x))\n",
    "\n",
    "def run(): \n",
    "    # itter = itterProgress(trainX)\n",
    "\n",
    "    for epoch in range(maxEpochs):\n",
    "        train(epoch)\n",
    "\n",
    "    torch.save(model.state_dict(), \"trained_model.pth\")\n",
    "    \n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for i, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "        indata, target = batch_x.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        indata = indata.unsqueeze(1)\n",
    "        out = model(indata)\n",
    "        out_softmax = torch.softmax(out, 1)\n",
    "        img = postprocess(out_softmax)\n",
    "        \n",
    "        train_acc = iou(img, target)\n",
    "        loss = criterion(out, target)\n",
    "        train_loss = loss.item()\n",
    "        \n",
    "        trainingAcc.append(train_acc)\n",
    "        trainingLoss.append(train_loss)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        val_acc, val_loss = validate()\n",
    "\n",
    "        validationAcc.append(val_acc)\n",
    "        validationLoss.append(val_loss)\n",
    "\n",
    "        logger.info(f\"Epoch {epoch} batch {i+1}/{len(train_dataloader)} loss={train_loss} acc={train_acc} val_loss={val_loss} val_acc={val_acc}\")\n",
    "\n",
    "        if val_loss > np.mean(validationLoss):\n",
    "            print(\"Overfitting detected\")\n",
    "            break\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    validationAcc_temp = []\n",
    "    validationLoss_temp = []\n",
    "    for i, (batch_x, batch_y) in enumerate(val_dataloader):\n",
    "        indata, target = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            indata = indata.unsqueeze(1)\n",
    "            out = model.forward(indata)\n",
    "            out_softmax = torch.softmax(out, 1)\n",
    "            img = postprocess(out_softmax)\n",
    "            \n",
    "            val_acc = iou(img, target)            \n",
    "            loss = criterion(out, target)\n",
    "            val_loss = loss.item()\n",
    "\n",
    "            validationAcc_temp.append(val_acc)\n",
    "            validationLoss_temp.append(val_loss)\n",
    "    \n",
    "    return np.mean(validationAcc_temp),np.mean(validationLoss_temp)\n",
    "\n",
    "def postprocess(img):\n",
    "    img = torch.argmax(img, dim=1)\n",
    "    img = img.cpu().numpy()\n",
    "    img = np.squeeze(img)\n",
    "    img = torch.from_numpy(img).type(torch.int64)\n",
    "    img = img.to(device)\n",
    "    # img = re_normalize(img)\n",
    "    return img\n",
    "\n",
    "def iou(prediction, target):\n",
    "    eps = 0\n",
    "    score = 0\n",
    "\n",
    "    for k in range(1, 10):\n",
    "        intersection = torch.sum((prediction==target) * (target==k)).item()\n",
    "        union = torch.sum(prediction==k).item() + torch.sum(target==k).item()\n",
    "        iou_k = 0 if intersection == 0 else (intersection + eps) / (union + eps)\n",
    "        score += iou_k\n",
    "\n",
    "    score = score / 9\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(validationLoss)\n",
    "plt.plot(trainingLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(validationAcc)\n",
    "plt.plot(trainingAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'trained_model_18.pth'\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "def model_val():\n",
    "    model.eval()\n",
    "\n",
    "    for i, (batch_x, batch_y) in enumerate(val_dataloader):\n",
    "        indata, target = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            indata = indata.unsqueeze(1)\n",
    "            out = model.forward(indata)\n",
    "            out_softmax = torch.softmax(out, 1)\n",
    "            img = postprocess(out_softmax)\n",
    "            \n",
    "            val_acc = iou(img, target)            \n",
    "            loss = criterion(out, target)\n",
    "            val_loss = loss.item()\n",
    "\n",
    "            print('acc={%f}, loss={%f}' % (val_acc, val_loss))\n",
    "\n",
    "            print_target_vs_out(target, img, indata.squeeze(1))\n",
    "\n",
    "\n",
    "def print_target_vs_out(target, outimg, x):\n",
    "    n_batch = x.shape[0]\n",
    "    fig = plt.figure()\n",
    "    for i in range(x.shape[0]):\n",
    "        ax1 = fig.add_subplot(n_batch, 3, i * 3 + 1)\n",
    "        ax1.imshow(x[i], cmap=\"gray\")\n",
    "        ax2 = fig.add_subplot(n_batch, 3, i * 3 + 2)\n",
    "        ax2.imshow(target[i], cmap=\"gray\")\n",
    "        ax3 = fig.add_subplot(n_batch, 3, i * 3 + 3)\n",
    "        ax3.imshow(outimg[i], cmap=\"gray\") \n",
    "    fig.show()\n",
    "           \n",
    "model_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python380jvsc74a57bd0778c709b60e40e6eabd44100ef7be5ae1872ed437ec46128456490bb70151712",
   "display_name": "Python 3.8.0 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "778c709b60e40e6eabd44100ef7be5ae1872ed437ec46128456490bb70151712"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}